\chapter{GMC\_NS.jl: Nested sampling by Galilean Monte Carlo for biological models}
\label{chap:GMC}
\path{GMC_NS.jl} implements a basic Galilean Monte Carlo nested sampler \cite{Skilling2012,Skilling2019} in pure Julia. It uses the updated Galilean reflection scheme of Skilling's later GMC publication \cite{Skilling2019}, which improves the algorithm's performance and preserves detailed balance. It uses the natural attrition of model-particles getting stuck in posterior modes to regulate the number of live particles in the model ensemble. This approach achieves the same end as algorithms which dynamically adjust the ensemble size based on parameters of the ensemble \cite{Feroz2009,Higson2019}, without any computational overhead or additional objective function. A minimum ensemble size may be supplied by the user, which is maintained by initializing a new trajectory isotropically from the position of an existing particle; this ensures that the ensemble may be sampled to convergence even if the number of trajectories started with is insufficient to guarantee this. 

\section{Implementation notes}

The basic sampling scheme followed is, first, to initialize an ensemble of models with parameters sampled evenly from across the prior, then to compress the ensemble to the posterior by applying GMC moves to the least-likely model in the ensemble at a given iterate, constrained by its current likelihood (which is the ensemble's likelihood contour for that iterate). GMC tends to move model-particles across the parameter space very efficiently, particularly in the initial portion of compression across the uninformative bulk of the prior mass. That said, GMC particles may get "stuck" in widely separated minima, so there are instances when the least-likely particle has no valid GMC moves. In this case, the trajectory is not continued. Instead, sampling continues, unless the number of particles in the ensemble would decline below the specified minimum. In this case, a new trajectory is begun by resampling from the remaining prior mass within the ensemble. This is accomplished by random "diffusive" proposals, in contrast to the ordinary, directed Galilean movements. This means a random particle remaining within the ensemble is selected, and isotropic velocity vectors are sampled from this particle to find a starting location for the new trajectory (this vector is conferred to the new particle).

\path{GMC_NS.jl} follows the common convention of transforming parameter space to a unit-standardized hypersphere. The user is responsible for ensuring that the density of the prior is uniform, that is $\pi(x) = 1$, over the -1:+1 range of the hypersphere dimension. Utility functions \path{to_unit_ball} and \path{to_prior} which accept the prior and transformed positions and the relevant prior probability distribution, returning the unit hypersphere or prior coordinate, respectively. In future versions, this scheme is likely to be modified to a 0:1 unit hypercube, which does not require additional operations beyond obtaining the cumulative probability of a parameter value on the prior distribution. The user may also specify a sampling "box" to bound particles from illegal or nonsensical areas of the parameter space (eg. negative values for continuous distributions on positive-valued physical variables). The box reflects particles specularly in the same manner as the likelihood boundary, with the exception that because the orientation of the $n$th-dimensional box "side" is known (eg. is the plane at $n=0$.), the reflection is performed by stopping the particle at the box side and giving it a new velocity vector identical to the old but with reversed sign in dimension $n$. 

\path{GMC_NS.jl} attempts to maintain efficient GMC sampling by per-particle PID tuning of the GMC timestep. GMC treats models as particles defined by their parameter vectors, which give their positions in parameter space, as well as a velocity vector, normally chosen isotropically and only changed when the particle "reflects" off the ensemble's likelihood contour. In GMC, when a model-particle is to be moved through the parameter space (in this case, because it is the least likely particle in the ensemble), a new position is proposed by extending some distance along its velocity vector. This distance is determined by scaling the velocity vector by a "timestep" value, which defines the per-iterate rate at which the particle traverses the parameter space. As the model ensemble is compressed to the posterior, this timestep must decline fairly evenly in order for GMC to be efficient, as the amount of available parameter space declines rapidly. Additionally, GMC particles may enter convoluted regions of parameter space that form small likelihood-isthmuses to other, more likely regions. In order to deal with this, each trajectory is assigned its own PID tuner, which maintains an independent timestep for the trajectory, tuned to target a user-supplied unobstructed move rate (given as a fraction in the range 0:1). In short, this will reduce the timestep if the particle is repeatedly reflecting off the likelihood boundary (in which case it is crossing the remaining prior mass without sampling much from within it, or it is in a highly convoluted area of the local likelihood surface), and extend the timestep if it repeatedly moves without encountering the boundary, so that particles that are closely sampling an open region without encountering the boundary begin to "speed up".

\section{Ensemble, Model, and Model Record interfaces}
In operation, \path{GMC_NS.jl} maintains an \path{GMC_NS_Ensemble} mutable struct in memory. The directory to which the sampler ought to save the ensemble is specified by its \path{path} field. \path{GMC_NS.jl} does not maintain calculated models in memory, instead serializing them to this directory. In order to track the positions and likelihoods of model-particles within the ensemble and as samples from the posterior, a \path{GMC_NS_Ensemble} maintains two vectors of \path{GMC_NS_Model_Records} as fields; \path{models} for live particles, and \path{posterior_samples} for the previous positions along trajectories. Observations against which models are being scored, prior distributions on model parameters, model constants (if any), and the sampling box are specified by the \path{GMC_NS_Ensemble}'s \path{obs}, \path{priors}, \path{constants}, and \path{box} fields, respectively. The \path{GMC_NS_Ensemble} also specifies settings for the GMC sampler and the PID tuner. Sensible defaults for these values may be passed en masse to an ensemble constructor with the \path{GMC_DEFAULTS} constant exported by \path{GMC_NS.jl}.

Therefore, to use \path{GMC_NS.jl} with their model, the user must write a model-appropriate version of these three structs with the fields specified by the docstrings in the \path{/src/ensemble/GMC_NS_Ensemble.jl} file, as well as \path{/src/GMC_NS_Model.jl}. The user is responsible for an appropriate constructor and likelihood function for the model, any required parameter bounding functions, and so on. The user may optionally write a overloaded \path{Base.show(io::IO, m::GMC_NS_Model)} function for displaying the model, or a \path{Base.show(io::IO, m::GMC_NS_Model, e::GMC_NS_Ensemble)} function for displaying the model with observations. This function can be used with the package's \path{ProgressMeter} displays for on-line monitoring of the current most likely model.

\section{Usage notes}
\subsection{Setting up for a run}
Given an appropriately coded model, as outlined above, the user must define a number of important values for the sampler before a \path{GMC_NS_Ensemble} may be constructed. These values are stored in fields of the ensemble. Firstly, the user must prepare the observation data in whatever format is suitable for the model's likelihood function. Next, one must define a vector of \path{Distribution}s on parameters of the model as the \path{prior} field of the ensemble. These must be univariate, as the CDF defines the position on that dimension. Some functions to produce univariate marginal distributions from multivariate Normal Gamma and Normal Inverse Gamma priors are available in \path{NGRefTools.jl}. Next, any constants used in the likelihood function must be available in the \path{constants} field of the ensemble. A \path{box} matrix with $n$-dimensional rows containing minimum and maximum values in the first and second columns defines the maximum extent of parameter space to be explored. The sampler expects the box in the transformed hypercoordinates mentioned above; a one-dimensional box across the entire prior would be \path{[-1 1]}. It is convenient to compose the matrix in the original parameter space and perform the transformation with a broadcast call to \path{to_unit_ball}, either in the ensemble constructor or in the calculation script.

\subsection{PID tuner settings for GMC}
As noted, GMC particle timesteps are governed by individual PID controllers. These controllers are defined by a number of values which must be supplied as \path{GMC_NS_Ensemble} fields. These are summarized below:

\path{GMC_Nmin} (Integer): The minimum number of active model-particles in the ensemble. After the initial sample from the prior, new particles will only be generated when required to maintain this value; otherwise, when a valid proposal cannot be found for the current least-likely trajectory (i.e. the PID tuner drives the timestep below \path{GMC_}$\tau$\path{_death}), the nested sampling step consists of removing that particle to the posterior samples and moving on to the next live particle. 

\path{GMC_}$\tau$\path{_death} (Float): Value of $\tau$ timestep associated with a trajectory below which the particle is considered to be dead. This value is in hypersphere coordinates. It is reasonable to make it very small for likelihood functions with low or no Monte Carlo noise; it should be somewhat larger for functions with significant MC noise.

\path{GMC_init_}$\tau$ (Float): Initial value of the timestep for all trajectories. This applies to the particles assembled on ensemble construction; particles generated from diffusional resampling inherit the $\tau$ of their parent, but with the isotropic vector which generated the proposal for their current location.

\path{GMC_tune_}$\mu$ (Integer): Length of tuner memory; the proposal acceptance rate $\alpha$ is calculated over the previous $\mu$ sampling steps for this trajectory.

\path{GMC_tune_}$\alpha$ (Float): Target acceptance rate for proposals. Should generally be .8 or higher, depending on desired sampling density.

\path{GMC_tune_PID} (NTuple{3,Float}): kP, kI, and kD constants for the tuner. Keep in  mind that the range of values for $\alpha$ is 0.:1.; given a \path{GMC_tune_}$\alpha$ constant of .8, the maximum error that will be encountered is likewise .8, so the values of the constants will generally be much smaller than 1. As with most PID applications, kP should be the largest value, and in this case generally determines the number of searches conducted before \path{GMC_}$\tau$\path{_death} is reached. 

\path{GMC_timestep_}$\eta$ (Float): If this value is >0., a normally distributed error with a standard devation of $\tau \cdot $\path{GMC_timestep_}$\eta$ is applied to $\tau$ before calculating the GMC proposals, as suggested by \cite{Skilling2012}.

\path{GMC_reflect_}$\eta$ (Float): If this value is >0., it is used to perturb reflection vectors, as suggested by \cite{Skilling2012}. It should be a small value.

\path{GMC_exhaust_}$\sigma$ (Float): Scale parameter applied to ensemble size to determine the maximum number of unsuccessful searches to perform before terminating sampling. Can usefully be fairly large.

\subsection{Parallelization}
\path{GMC_NS.jl} does not have an explicit parallelization scheme; the sampler proceeds linearly to the next least-likely particle and performs the appropriate Galilean trajectory sampling procedure. Parallelization may nonetheless be achieved at two levels; the likelihood function may be parallel according to the needs of the user, and individual nested sampling runs may be arbitrarily combined. That is, if one desires to parallelize a \path{GMC_NS.jl} job, it is best to think in terms of the total number of trajectories to be sampled, dividing this by the number of machines available to perform the sampling work, to obtain the number of particles to be sampled on each machine. The sampling runs can then be combined post hoc to achieve the desired final accuracy. In this scheme, the likelihood function is best parallelized by threading on a single machine.

\subsection{Displays}
If desired, parameters of the ensemble and most-likely model can be monitored on-line, while \path{GMC_NS.jl} is working. This is done by specifying a vector of function vectors (ie a \path{Vector{Vector{Function}}}). One such vector may be supplied to specify the displays to be shown above the \path{ProgressMeter}, one for those below, supplied as the \path{upper_displays} or \path{lower_displays} keyword arguments to \path{converge ensemble!()}. \path{GMC_NS.jl} will rotate the upper and lower displays to the next vector of display functions every \path{disp_rot_its} sampling iterates, supplied as another \path{converge_ensemble!()} keyword argument. Default display functions are available in \path{/src/utilities/progress_displays.jl} and are exported for easy composition of the function vectors.

\subsection{Example use}